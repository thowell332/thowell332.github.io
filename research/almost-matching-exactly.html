<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Interpretable Machine Learning Research | Thomas J Howell</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<script src="../components/header.js" type="text/javascript" defer></script>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-M5HP379ESS"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'G-M5HP379ESS');
		</script>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header-component></header-component>

							<!-- Content -->
								<section>
									<p>
                                        <a href="../research.html">Research</a> > 
                                        <a href="./almost-matching-exactly.html">Interpretable Machine Learning for Causal Inference</a>
                                    </p>
                                    
                                    <header class="main">
										<h1 class="project-header">Interpretable Machine Learning for Causal Inference
                                        </h1>
                                        <p class="project-subheader">Almost Matching Exactly Lab<br/>May 2020 - present</p>
									</header>

									<!-- Content -->
                                        <div class="row">
                                            <p>
                                                <span class="image left"><img src="../images/ame-malts-graph.png" alt="" />
                                                    <strong>Figure 1:</strong> Heat map visualization of matched group matrix generated by MALTS. 
													(<a target="_blank" href="https://github.com/almost-matching-exactly/MALTS">source</a>)
                                                </span>
                                                <span class="header">Background and Research Goals</span><br/><br/>
                                                Machine learning models are becoming increasingly 
												relevant for decision-making in high stakes domains, such as 
												health care and criminal justice. In order to maintain trust 
												in the model and to avoid potentially disastrous consequences,
												it is very important to design human-interpretable machine learning 
												tools. For clarity, an interpretable model is one where the underlying 
												logic and reasoning can be understood by humans. In contrast, 
												a "black box" model is one which is either far too complicated for a 
												human to discern or one which is proprietary, so users are 
												forbidden from understanding the mechanisms under the hood.
												Headed by Dr. Sudeepa Roy, Dr. Cynthia Rudin, and Dr. Alexander Volfovsky, 
												the <a target="_blank" href="https://almost-matching-exactly.github.io/">Almost Matching Exactly Lab</a>
												at Duke University focuses on developing and applying <i>interpretable</i> machine learning algorithms 
												for causal inference. My individual contributions to the lab deal primarily
												with the <a target="_blank" href="https://almost-matching-exactly.github.io/DAME-FLAME-Python-Package/">DAME-FLAME Python Package</a>,
												the creation and maintenance of the AME website, and the interactive demo created for the 
												Conference on Neural Information Processing Systems (NeurIPS).
                                            </p>
                                        </div>
										<h2>Manuscripts</h2>
										<a target="_blank" href="https://arxiv.org/abs/2101.01867">
											dame-flame: A Python Library Providing Fast Interpretable Matching for Causal Inference
										</a>. Neha R. Gupta, Vittorio Orlandi, Chia-Rui Chang, Tianyu Wang, 
										Marco Morucci, Pritam Dey, Thomas J. Howell, Xian Sun, Angikar Ghosal, Sudeepa Roy, 
										Cynthia Rudin, Alexander Volfovsky

                                </section>
                        </div>
                    </div>

				<!-- Sidebar -->
                    <div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<!-- <section id="search" class="alt">
									<form style="z-index: -100" method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search"/>
									</form>
								</section> -->

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="../index.html">Home</a></li>
										<li><a href="../projects.html">Projects</a></li>
										<li><a href="../research.html">Research</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Contact me</h2>
									</header>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="mailto:thomas.howell@duke.edu">thomas.howell@duke.edu</a></li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Thomas J Howell. All rights reserved. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

        </div>

    <!-- Scripts -->
        <script src="../assets/js/jquery.min.js"></script>
        <script src="../assets/js/browser.min.js"></script>
        <script src="../assets/js/breakpoints.min.js"></script>
        <script src="../assets/js/util.js"></script>
        <script src="../assets/js/main.js"></script>

</body>
</html>